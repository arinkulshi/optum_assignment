{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Questions\n",
    "1. Modify the training script so that only 80% of the data is used for training and the remaining 20% is test data.\n",
    "\n",
    "2. Output the accuracy score of the model on the test data.\n",
    "\n",
    "3. Implement a simple cross-validation step to find which of 1, 5, and 10 is the best max_depth for the classifier\n",
    "\n",
    "4. Print the confusion matrix of the classifier that results from (3) using sklearn's built-in method. Which class has the most false positives?\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "features = data[\"data\"]\n",
    "labels = data[\"target\"]\n",
    "\n",
    "\n",
    "#confusion_matrix(labels, pred)\n",
    "\n",
    "#Accuracy = (Number of elements correctly classified)/(Total elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Modify the training script so that only 80% of the data is used for training and the remaining 20% is test data.\n",
    "\n",
    "2. Output the accuracy score of the model on the test data.\n",
    "\n",
    "3. Implement a simple cross-validation step to find which of 1, 5, and 10 is the best max_depth for the classifier\n",
    "\n",
    "4. Print the confusion matrix of the classifier that results from (3) using sklearn's built-in method. Which class has the most false positives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of observations = 150, with multi-class label value [0, 1, 2]\n",
      "Number of observations in Training set = 120 and in Test set = 30 after 80-20 split\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#Modify the training script so that only 80% of the data is used for training and the remaining 20% is test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2)\n",
    "\n",
    "multi_class_value = (list(set(labels)))\n",
    "\n",
    "no_of_total_observation = len(labels)\n",
    "\n",
    "print (f'Total number of observations = {no_of_total_observation}, with multi-class label value {multi_class_value}')\n",
    "print (f'Number of observations in Training set = {len(y_train)} and in Test set = {len(y_test)} after 80-20 split' )\n",
    "#Implement a simple cross-validation step to find which of 1, 5, and 10 is the best max_depth for the classifier\n",
    "#Output the accuracy score of the model on the test data.\n",
    "max_depth_values = [1,5,10]\n",
    "accuracies = {}\n",
    "false_positives = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"During my repeated training and validation process (which is in the for loop below) on the same train and test split\n",
    "I get a small variation on test prdiction and test accuracy. Let me attach that for your refererence. \n",
    "This dictionary has two elements; Accuracy Score value and the confusion matrix.\n",
    "\n",
    "{1: [0.6333333333333333, array([\n",
    "\t   [12,  0,  0],\n",
    "       [ 0,  0, 11],\n",
    "       [ 0,  0,  7]], dtype=int64)], \n",
    " 5: [0.9666666666666667, array([\n",
    "       [12,  0,  0],\n",
    "       [ 0, 11,  0],\n",
    "       [ 0,  1,  6]], dtype=int64)], \n",
    " 10: [1.0, array([\n",
    "       [12,  0,  0],\n",
    "       [ 0, 11,  0],\n",
    "       [ 0,  0,  7]], dtype=int64)]}\n",
    "\t   \n",
    "{1: [0.6333333333333333, array([\n",
    "\t   [12,  0,  0],\n",
    "       [ 0,  0, 11],\n",
    "       [ 0,  0,  7]], dtype=int64)], \n",
    " 5: [0.9666666666666667, array([\n",
    "       [12,  0,  0],\n",
    "       [ 0, 11,  0],\n",
    "       [ 0,  1,  6]], dtype=int64)], \n",
    " 10: [0.9666666666666667, array([\n",
    "       [12,  0,  0],\n",
    "       [ 0, 11,  0],\n",
    "       [ 0,  1,  6]], dtype=int64)]}\n",
    "\n",
    "\t   \n",
    "{1: [0.6333333333333333, array([\n",
    "\t   [12,  0,  0],\n",
    "       [ 0,  0, 11],\n",
    "       [ 0,  0,  7]], dtype=int64)], \n",
    " 5: [1.0, array([\n",
    "\t   [12,  0,  0],\n",
    "       [ 0, 11,  0],\n",
    "       [ 0,  0,  7]], dtype=int64)], \n",
    " 10: [0.9666666666666667, array([\n",
    "\t   [12,  0,  0],\n",
    "       [ 0, 11,  0],\n",
    "       [ 0,  1,  6]], dtype=int64)]}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for i in max_depth_values:\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction_test_data = model.predict(X_test)\n",
    "    #accuracies.append(accuracy_score(y_test,prediction_test_data))\n",
    "    accuracies_list = []\n",
    "    #accuracies_list.append(accuracy_score(y_test,prediction_test_data))\n",
    "    #accuracies_list.append(confusion_matrix(y_test,prediction_test_data))\n",
    "    conf_matrix = confusion_matrix(y_test,prediction_test_data)\n",
    "    accuracies[i] = [accuracy_score(y_test,prediction_test_data),confusion_matrix(y_test,prediction_test_data)]\n",
    "#print(accuracies)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following are the results from Decision Tree model with Max Depth Value 1\n",
      "=======================================================================\n",
      "Accuracy score : 0.7\n",
      "Confusion matrix for the max depth value 1 of Decision Tree model\n",
      "---------------------------------------------------------------------\n",
      "Prediction count for different classes, Column represents Predicted value, Row represents Actual Value\n",
      "  Y=0 Y=1 Y=2\n",
      "  12   0   0\n",
      "   0   9   0\n",
      "   0   9   0\n",
      "False positive prediction from Decision Tree model [0, 9, 0] for corresponding Y values: [0, 1, 2]\n",
      "Maximum False positive found for class 1 with False-Positive count 9 \n",
      "\n",
      "\n",
      "Following are the results from Decision Tree model with Max Depth Value 5\n",
      "=======================================================================\n",
      "Accuracy score : 1.0\n",
      "Confusion matrix for the max depth value 5 of Decision Tree model\n",
      "---------------------------------------------------------------------\n",
      "Prediction count for different classes, Column represents Predicted value, Row represents Actual Value\n",
      "  Y=0 Y=1 Y=2\n",
      "  12   0   0\n",
      "   0   9   0\n",
      "   0   0   9\n",
      "False positive prediction from Decision Tree model [0, 0, 0] for corresponding Y values: [0, 1, 2]\n",
      "Maximum False positive found for class 0 with False-Positive count 0 \n",
      "\n",
      "\n",
      "Following are the results from Decision Tree model with Max Depth Value 10\n",
      "=======================================================================\n",
      "Accuracy score : 1.0\n",
      "Confusion matrix for the max depth value 10 of Decision Tree model\n",
      "---------------------------------------------------------------------\n",
      "Prediction count for different classes, Column represents Predicted value, Row represents Actual Value\n",
      "  Y=0 Y=1 Y=2\n",
      "  12   0   0\n",
      "   0   9   0\n",
      "   0   0   9\n",
      "False positive prediction from Decision Tree model [0, 0, 0] for corresponding Y values: [0, 1, 2]\n",
      "Maximum False positive found for class 0 with False-Positive count 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Please note that the confusion matrix in scikit-learn has been generated using \n",
    "Column_value = Predicted value and Row_value = Actual value. \n",
    "let me describe the computation logic for False Positive values for the the classes. \n",
    "Please note that we have 3 classes here for predicted Y values; 0,1,2\n",
    "Example for calculation for false positive for the class 0,1 and 2\n",
    "false_positive_class0 =confusion_matrix[1][0] + confusion_matrix[2][0]\n",
    "false_positive_class1 =confusion_matrix[0][1] + confusion_matrix[2][1]\n",
    "false_positive_class2 =confusion_matrix[0][2] + confusion_matrix[1][2]\n",
    "\n",
    "Please note that this is a column based aggegation\n",
    "'''\n",
    "\n",
    "\n",
    "for inxi,accuracy in accuracies.items():\n",
    "#Initializing the counter that holds false positive for three predicted class values i.e. 0,1,2    \n",
    "    false_positive = [0] * len(multi_class_value)\n",
    "\n",
    "#Getting the confusion matrix element from the accuracies dictionary which is the 2nd element    \n",
    "    confusion_matrix = accuracy[1]\n",
    "#    print(conf_matrix)\n",
    "    for inxj, actual_value_row  in enumerate(confusion_matrix):\n",
    "     #   print(inxj, j)\n",
    "        for inxk, predicted_value in enumerate(actual_value_row):\n",
    "            if inxj == inxk:\n",
    "                pass\n",
    "            else:\n",
    "#                print(inxj,inxk)\n",
    "                false_positive[inxk] = false_positive[inxk] + predicted_value\n",
    "    print(f'Following are the results from Decision Tree model with Max Depth Value {inxi}')\n",
    "    print(f'=======================================================================')\n",
    "    print(f'Accuracy score : {accuracy[0]}')\n",
    "    print(f'Confusion matrix for the max depth value {inxi} of Decision Tree model')\n",
    "    print(f'---------------------------------------------------------------------')\n",
    "    print(f'Prediction count for different classes, Column represents Predicted value, Row represents Actual Value')\n",
    "    print(f'  Y={multi_class_value[0]} Y={multi_class_value[1]} Y={multi_class_value[2]}')\n",
    "    print('\\n'.join([''.join(['{:4}'.format(true_false_count) for true_false_count in row_counts]) for row_counts in accuracy[1]]))\n",
    "    \n",
    "    print(f'False positive prediction from Decision Tree model {false_positive} for corresponding Y values: {multi_class_value}' )\n",
    "    max_false_positive_value = max(false_positive)\n",
    "    print(f'Maximum False positive found for class {false_positive.index(max_false_positive_value)} with False-Positive count {max_false_positive_value} \\n\\n')\n",
    "\n",
    "\n",
    "#for values in accuracies.items():\n",
    "    #print(values[1][0][1])\n",
    "\n",
    "#Print the confusion matrix of the classifier that results from (3) using sklearn's built-in method. Which class has the most false positives?\n",
    "\n",
    "#{1:}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
